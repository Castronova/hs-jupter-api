{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Time Series Analysis\n",
    "\n",
    "This notebook demonstrates basic time series data analysis using scientific Python libraries such as [NumPY](http://www.numpy.org/).  This example uses air temperature data that is stored in HydroShare to derive daily aggregated values and store them in a new HydroShare resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Script Setup and Preparation\n",
    "\n",
    "Before we begin our processing, we must import several libaries into this notebook. The `hs_utils` library provides functions for interacting with HydroShare, including resource querying, dowloading and creation.  The `%matplotlib inline` command tells the notebook server to place plots and figures directly into the notebook.\n",
    "\n",
    "**Note:** You may see some matplotlib warnings if this is the first time you are running this notebook. These warnings can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import required libaries\n",
    "import os\n",
    "import hs_utils\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to establish a secure connection with HydroShare. This is done by simply instantiating the hydroshare class that is defined within `hs_utils`. In addition to connecting with HydroShare, this command also sets environment variables for several parameters that may useful to you:\n",
    "\n",
    "1. Your username\n",
    "2. The ID of the resource which launched the notebook\n",
    "3. The type of resource that launched this notebook\n",
    "4. The url for the notebook server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# establish a secure connection to HydroShare\n",
    "hs = hs_utils.hydroshare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve a resource using its ID\n",
    "\n",
    "This example uses temperature data that is stored in HydroShare at the following url: https://www.hydroshare.org/resource/927094481da54af38ffb6f0c39ad8787/ . The data for our processing routines can be retrieved using the `getResourceFromHydroShare` function by passing it the global identifier from the url above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get some resource content. The resource content is returned as a dictionary\n",
    "content = hs.getResourceFromHydroShare('927094481da54af38ffb6f0c39ad8787')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One file was downloaded to the Python notebook server: \n",
    "\n",
    "1. BeaverDivideTemp.csv\n",
    "\n",
    "\n",
    "We will be using this file to derive daily minimum, maximum, and average air temperatures.  Lets preview this Beaver Divide temperature data by looping over the first 10 lines of the csv file that was downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preview the content of the BeaverDivideTemp file\n",
    "air_temp_csv = hs.content['BeaverDivideTemp.csv']\n",
    "with open(hs.content['BeaverDivideTemp.csv']) as f:\n",
    "    for i in range(0, 10):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Series Analysis\n",
    "\n",
    "NumPY is a numerical library that we will be using to read and analyze this temperature data.  To get started, the `genfromtxt` command is used to parse the textfile into NumPY arrays.  This is a powerful function that allows us to skip commented lines, strip whitespace, as well as transform date strings into python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read all of the data into a numpy array\n",
    "data = np.genfromtxt(air_temp_csv, comments='#', delimiter=',',autostrip=True,\n",
    "                    converters={0: lambda x: datetime.strptime(x.decode(\"utf-8\"), \n",
    "                                                               '%m-%d-%Y %H:%M:%S')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in deriving daily aggregated temperatures, we need to summarize the temperature data by date.  The `itertools` library provides an efficient way for us to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# group the temperature data by day\n",
    "start = data[0][0]\n",
    "lenperiod = 1\n",
    "\n",
    "# lists to hold the grouped temperatures and dates\n",
    "grouped_data = []\n",
    "grouped_dates = []\n",
    "\n",
    "ind = 0\n",
    "for k, g in it.groupby(data,lambda data: (data[0]-start).days // lenperiod):\n",
    "    group = list(g)\n",
    "    grouped_dates.append(group[0][0])\n",
    "    d = [g[1] for g in group if g[1] != -9999]\n",
    "    grouped_data.append(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all of the data has been read into memory and grouped by date, we can simply loop over each day an calculate the min, max, and average temperature values.  Note that we are considering any value that is less than -80 $^\\circ C$ to be erroneous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize the t_min, t_max, and t_ave arrays\n",
    "t_min = np.full((len(grouped_dates), 1),  9999, dtype=np.float)\n",
    "t_max = np.full((len(grouped_dates), 1), -9999, dtype=np.float)\n",
    "t_ave = np.full((len(grouped_dates), 1), 0, dtype=np.float)\n",
    "\n",
    "# loop over every day\n",
    "for i in range(len(grouped_dates)):\n",
    "    temp_count = 0\n",
    "    # loop over each recorded temperature \n",
    "    for temp in grouped_data[i]:        \n",
    "        # skip nodata values and any value less than -80 C\n",
    "        if temp > -80:\n",
    "            # save the min temp\n",
    "            if temp < t_min[i]:\n",
    "                t_min[i] = temp\n",
    "            # save the max temp\n",
    "            if temp > t_max[i]:\n",
    "                t_max[i] = temp\n",
    "            # sum the temps\n",
    "            t_ave[i] += temp\n",
    "            temp_count += 1\n",
    "    # calculate the average temp\n",
    "    t_ave[i] = (t_ave[i] / temp_count).round(2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize our derived data by using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a figure\n",
    "fig, ax = plt.subplots(1,1,figsize=(15, 5))\n",
    "\n",
    "# plot each temperature time series\n",
    "tmax = ax.plot_date(grouped_dates, t_max, 'g-', label='Maximum Temperature')\n",
    "tave = ax.plot_date(grouped_dates, t_ave, 'b-', label='Average Temperature')\n",
    "tmin = ax.plot_date(grouped_dates, t_min, 'r-', label='Minimum Temperature')\n",
    "\n",
    "# display a legend\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend(h, l)\n",
    "\n",
    "# set the figure title\n",
    "fig.suptitle('Beaver Divide Temperatures')\n",
    "plt.ylabel('Temperature (degrees C)')\n",
    "\n",
    "# format the ticks\n",
    "ax.grid(True)\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data analysis is complete we need to save the results.  An easy way to accomplish this is to loop over the date range and write each of the arrays to a csv file.  We are using the built-in `os.environ['DATA']` variable to get the path of the default data directory, therefore, the resulting file will be located in the `data` directory on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the save path for the aggregated values\n",
    "temp_agg = os.path.join(os.environ['DATA'], 'beaver_divide_temp_daily_agg.csv')\n",
    "\n",
    "# write the derived temperatures to a csv file\n",
    "with open(temp_agg, 'w') as f:\n",
    "    f.write('Date, Ave Temp (C), Min Temp (C), Max Temp (C)\\n')\n",
    "    for i in range(len(grouped_dates)):\n",
    "        f.write('%s,%3.2f,%3.2f,%3.2f\\n' % \n",
    "               (grouped_dates[i].strftime('%m-%d-%Y'), t_ave[i], t_min[i], t_max[i]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Save the results back into HydroShare\n",
    "\n",
    "Using the `hs_utils` library, the results of our timeseries analysis can be saved back into HydroShare.  First, define all of the required metadata for resource creation, i.e. *title*, *abstract*, *keywords*, and *content files*.  In addition, we must define the type of resource that will be created, in this case *genericresource*.  \n",
    "\n",
    "***Optional*** : define the resource from which this \"new\" content has been derived.  This is one method for tracking resource provenance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define HydroShare required metadata\n",
    "title = 'Daily Aggregate Temperature for Beaver Divide'\n",
    "abstract = 'This daily average air temperature for the Beaver Divide gauging station that is maintained by iUtah researchers.'\n",
    "keywords = ['Temperatire', 'Beaver Divide', 'Time Series']\n",
    "\n",
    "# set the resource type that will be created.\n",
    "rtype = 'genericresource'\n",
    "\n",
    "# create a list of files that will be added to the HydroShare resource.\n",
    "files = [temp_agg]  \n",
    "\n",
    "# Set the Beaver Divide temperature resource as the \"parent\" \n",
    "# (i.e. the new resource will be \"derived from\" the \"927094481da54af38ffb6f0c39ad8787 resource)\n",
    "parent_resource = '927094481da54af38ffb6f0c39ad8787'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a hydroshare resource containing these data\n",
    "resource_id = hs.createHydroShareResource(abstract, \n",
    "                                          title, \n",
    "                                          derivedFromId=parent_resource,\n",
    "                                          keywords=keywords, \n",
    "                                          resource_type=rtype, \n",
    "                                          content_files=files, \n",
    "                                          public=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
