{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis Using ODM2\n",
    "\n",
    "This notebook demonstrates basic time series data analysis using scientific Python libraries such as [NumPY](http://www.numpy.org/). This example uses water temperature data that is stored in a HydroShare TimeSeries resource to derive daily aggregated values and store the results in a new HydroShare resource.\n",
    "\n",
    "\n",
    "## Script Setup and Preparation\n",
    "\n",
    "Before we begin our processing, we must import several libaries into this notebook. The `ts_utils` library provides functions for interacting HydroShare Time Series Resources, including data querying and dowloading.  The `hs_utils` function provides general purpose functions for interacting with HydroShare.  The `%matplotlib inline` command tells the notebook server to place plots and figures directly into the notebook.\n",
    "\n",
    "**Note:** You may see some matplotlib warnings if this is the first time you are running this notebook. These warnings can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "from utilities import timeseries\n",
    "import numpy as np\n",
    "import collections\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to establish a secure connection with HydroShare. This is done by simply instantiating the hydroshare class that is defined within `ts_utils`. In addition to connecting with HydroShare, this command also sets environment variables for several parameters that may useful to you:\n",
    "\n",
    "1. Your username\n",
    "2. The ID of the resource which launched the notebook\n",
    "3. The type of resource that launched this notebook\n",
    "4. The url for the notebook server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# establish a secure connection to HydroShare\n",
    "ts = timeseries.timeseries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve a time series resource using its ID\n",
    "\n",
    "This example uses water temperature data that is stored in HydroShare at the following url: https://www.hydroshare.org/resource/c6df8c1f22a0452b8035198e72967364/ . The data for our processing routines can be retrieved using the `getTimeSeriesResource` function by passing it the global identifier from the url above.  Alternatively, you can invoke the `getTimeSeriesResource` function without any arguments to retrieve data for the resource that launched your JupyterHub instance from HydroShare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Invoke the getTimeSeriesResource with the following guid to download \n",
    "# Water temperature data from the Little Bear River, UT\n",
    "#\n",
    "# ts.getTimeSeriesResource('c6df8c1f22a0452b8035198e72967364')\n",
    "\n",
    "# Alternatively, invoke the getTimeSeriesResource without any arguments\n",
    "# to download the content for the resource that you launched in HydroShare\n",
    "ts.getTimeSeriesResource()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Database Contents\n",
    "\n",
    "TimeSeries resources consist of data stored in the Observations Data Model version 2. We can use the `ts_utils` and `odm2api` libraries to explore the contents of the database.  For more information on `odm2api` functions see https://github.com/ODM2/ODM2PythonAPI or issue the following command:\n",
    "\n",
    "`help(odm2api)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display all variables inside the database\n",
    "print('\\n-------- Variables ---------')\n",
    "print('%-10s %-10s\\n%-10s %-10s' % ('Code', 'Name', '----','----'))\n",
    "for x in ts.read.getVariables():\n",
    "    print('%-10s %-10s' % (x.VariableCode, x.VariableNameCV))\n",
    "print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all of the people from the database\n",
    "print('\\n-------- People ---------')\n",
    "print('%-10s %-10s\\n%-10s %-10s' % ('First', 'Last', '-----','-----'))\n",
    "for x in ts.read.getPeople():\n",
    "    print('%-10s %-10s' % (x.PersonFirstName, x.PersonLastName))\n",
    "print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all of the SamplingFeatures from the database that are Sites\n",
    "siteFeatures = ts.read.getSamplingFeatures(type='Site')\n",
    "print('\\n-------------------------------- Sites ---------------------------------')\n",
    "print('%-20s %-20s\\n%-20s %-20s' % ('Code', 'Name', '-----','-----'))\n",
    "for x in siteFeatures:\n",
    "        print('%-20s %-20s' % (x.SamplingFeatureCode, x.SamplingFeatureName[:50]))\n",
    "print('--------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the results into the ts_utils library\n",
    "results = ts.readResults()\n",
    "print('\\n-------------------------------- Results ---------------------------------')\n",
    "print('%-10s %-10s %-10s %-20s %-20s' % ('ResultID','VariableID','ValueCount','VariableName','FeatureCode'))\n",
    "for x in results.values():\n",
    "    print('%-10d %-10s %-10d %-20s %-20s' % (x.ResultID,\n",
    "                                          x.VariableID,\n",
    "                                          x.ValueCount,\n",
    "                                          x.VariableObj.VariableNameCV,\n",
    "                                          x.FeatureActionObj.SamplingFeatureObj.SamplingFeatureCode))\n",
    "print('--------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the datavalues from the ODM2 database\n",
    "\n",
    "Now that we've explored some of the data in the odm2 database, we can use the `ts_utils` library to parse the data into objects.  These object provide an easy way for us to preview, plot, and retrieve the datavalues associated the each time series result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the timeseries values for result ids 1,2, and 3 into memory\n",
    "ts.readTsValues([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preview these data\n",
    "ts.previewTs([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preview the data as set of subplots\n",
    "ts.subplotTimeSeries(ids=[1,2,3,4], cols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot multiple data series on a single graph\n",
    "ts.plotTimeSeries(ids=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Analysis\n",
    "\n",
    "The data previewing (above) isolate a single dataset to analyze.  In this example, we will be calculating the minimum, maximum, and average water temperature values for a `ResultID=1`: *Little Bear River at Mendon Road near Mendon, UT*. \n",
    "\n",
    "First, group the temperature datavalues by day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the data that we want to analyze\n",
    "data = ts.tsvalues[1]  # pandas dataframe\n",
    "res = ts.tsresults[1]  # odm2result object\n",
    "\n",
    "dates = [datetime.strptime(str(d), '%Y-%m-%d %H:%M:%S') for d in data['ValueDateTime']]\n",
    "vals = data['DataValue']\n",
    "\n",
    "# group the temperature data by day\n",
    "start = dates[0]\n",
    "lenperiod = 1  # 1 day\n",
    "\n",
    "# lists to hold the grouped temperatures and dates\n",
    "gv = collections.OrderedDict() \n",
    "for i in range(len(dates)):\n",
    "    date = dates[i].strftime('%m-%d-%Y')\n",
    "    if date in gv.keys():\n",
    "        gv[date].append(vals[i])\n",
    "    else:\n",
    "        gv[date] = [vals[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will summarize the daily aggregated water temperatures and calculate daily minimum, maximum, and average values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize the t_min, t_max, and t_ave arrays\n",
    "t_min = np.full((len(gv), 1),  9999, dtype=np.float)\n",
    "t_max = np.full((len(gv), 1), -9999, dtype=np.float)\n",
    "t_ave = np.full((len(gv), 1), 0, dtype=np.float)\n",
    "\n",
    "# loop over every day\n",
    "date_idx = 0\n",
    "for date in gv.iterkeys():\n",
    "    temp_count = 0\n",
    "    # loop over each recorded temperature \n",
    "    for temp in gv[date]:        \n",
    "        # save the min temp\n",
    "        if temp < t_min[date_idx]:\n",
    "            t_min[date_idx] = temp\n",
    "        # save the max temp\n",
    "        if temp > t_max[date_idx]:\n",
    "            t_max[date_idx] = temp\n",
    "        # sum the temps\n",
    "        t_ave[date_idx] += temp\n",
    "        temp_count += 1\n",
    "\n",
    "    # calculate the average temp\n",
    "    t_ave[date_idx] = (t_ave[date_idx] / temp_count).round(2)\n",
    "    \n",
    "    date_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the water temperature data is aggregated and summarized, we can preview the results using `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a figure\n",
    "fig, ax = plt.subplots(1,1,figsize=(15, 5))\n",
    "\n",
    " # plot each temperature time series\n",
    "x = [datetime.strptime(d, '%m-%d-%Y') for d in gv.keys()]\n",
    "tmax = ax.plot_date(x, t_max, 'g-', label='Maximum Temperature')\n",
    "tave = ax.plot_date(x, t_ave, 'b-', label='Average Temperature')\n",
    "tmin = ax.plot_date(x, t_min, 'r-', label='Minimum Temperature')\n",
    "\n",
    "# display a legend\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend(h, l)\n",
    "\n",
    "# set the figure title\n",
    "res = ts.tsresults[1]\n",
    "fig.suptitle(res.FeatureActionObj.SamplingFeatureObj.SamplingFeatureName, fontsize=14)\n",
    "plt.ylabel('Temperature (degrees C)')\n",
    "\n",
    "# format the ticks\n",
    "ax.grid(True)\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write these results to a CSV text file\n",
    "\n",
    "At this point our data analysis is complete and we need to save our calculations somewhere.  An easy way to accomplish this is to loop over the date range and write each of the arrays to a csv file.  We are using the built-in `os.environ['DATA']` variable to get the path of the default data directory, therefore, the resulting file will be located in the `data` directory on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the save path for the aggregated values\n",
    "temp_agg = os.path.join(os.environ['DATA'], 'agg.csv')\n",
    "\n",
    "# write the derived temperatures to a csv file\n",
    "with open(temp_agg, 'w') as f:\n",
    "    f.write('Date, Ave Temp (C), Min Temp (C), Max Temp (C)\\n')\n",
    "    for i in range(len(gv.keys())):\n",
    "        f.write('%s,%3.2f,%3.2f,%3.2f\\n' % \n",
    "               (gv.keys()[i], t_ave[i], t_min[i], t_max[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Save the results back into HydroShare\n",
    "\n",
    "Using the `hs_utils` library, the results of our timeseries analysis can be saved back into HydroShare.  First, define all of the required metadata for resource creation, i.e. *title*, *abstract*, *keywords*, and *content files*.  In addition, we must define the type of resource that will be created, in this case *genericresource*.  \n",
    "\n",
    "***Optional*** : define the resource from which this \"new\" content has been derived.  This is one method for tracking resource provenance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define HydroShare required metadata\n",
    "title = 'Daily Aggregate Temperature for Little Bear River near Mendon, UT'\n",
    "abstract = 'This daily average air temperature for the Little Bear River gauging station near Mendon, UT.'\n",
    "keywords = ['Water Temperature', 'Time Series']\n",
    "\n",
    "# set the resource type that will be created.\n",
    "rtype = 'genericresource'\n",
    "\n",
    "# create a list of files that will be added to the HydroShare resource.\n",
    "files = [temp_agg, # the aggregated data file\n",
    "         ts.odm2db, # the original odm2db\n",
    "         os.path.join(os.getcwd(), 'timeseries_odm2.ipynb')  # this notebook\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the state of the current notebook\n",
    "from IPython.display import display,Javascript \n",
    "display(Javascript('IPython.notebook.save_checkpoint();'))\n",
    "\n",
    "# create a hydroshare resource containing these data\n",
    "resource_id = ts.hydroshare.createHydroShareResource( abstract, \n",
    "                                                      title, \n",
    "                                                      derivedFromId=None,\n",
    "                                                      keywords=keywords, \n",
    "                                                      resource_type=rtype, \n",
    "                                                      content_files=files, \n",
    "                                                      public=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}